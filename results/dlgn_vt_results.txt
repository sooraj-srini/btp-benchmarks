4_50_3_1.0e-03
cuda
Current task:  6
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361060
Task URL.............: https://www.openml.org/t/361060
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: class
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:electricity
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5047, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.073279
Loss after updating value_net at epoch 100  is  tensor(0.4779, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.535775
Loss after updating value_net at epoch 200  is  tensor(0.4720, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.953679
Loss after updating value_net at epoch 300  is  tensor(0.4675, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.725138
Loss after updating value_net at epoch 400  is  tensor(0.4652, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.540351
Loss after updating value_net at epoch 500  is  tensor(0.4635, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4186764
Loss after updating value_net at epoch 600  is  tensor(0.4625, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4101887
Loss after updating value_net at epoch 700  is  tensor(0.4618, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.440008
Loss after updating value_net at epoch 800  is  tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4608235
Loss after updating value_net at epoch 900  is  tensor(0.4605, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4966865
Loss after updating value_net at epoch 1000  is  tensor(0.4603, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.498059
Loss after updating value_net at epoch 1100  is  tensor(0.4597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.5403485
Loss after updating value_net at epoch 1200  is  tensor(0.4596, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.550932
Loss after updating value_net at epoch 1300  is  tensor(0.4588, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.603879
Loss after updating value_net at epoch 1400  is  tensor(0.4580, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.6754785
Loss after updating value_net at epoch 1500  is  tensor(0.4577, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.6782913
Loss after updating value_net at epoch 1600  is  tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7014704
Loss after updating value_net at epoch 1700  is  tensor(0.4565, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7945294
Loss after updating value_net at epoch 1800  is  tensor(0.4551, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.954111
Loss after updating value_net at epoch 1900  is  tensor(0.4548, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.9581695
Loss after updating value_net at epoch 2000  is  tensor(0.4547, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.991667
Setup:
Num neurons :  [7, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 5901
Train loss =  tensor(0.4547, grad_fn=<NllLossBackward0>)
Num_train_data= 26931
Test error= 1774
Num_test_data= 8081
Test accuracy= 78.04727137730478
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5001, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4423485
Loss after updating value_net at epoch 100  is  tensor(0.4768, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.6639857
Loss after updating value_net at epoch 200  is  tensor(0.4703, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.0419846
Loss after updating value_net at epoch 300  is  tensor(0.4671, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.948816
Loss after updating value_net at epoch 400  is  tensor(0.4647, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8368526
Loss after updating value_net at epoch 500  is  tensor(0.4624, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.802231
Loss after updating value_net at epoch 600  is  tensor(0.4609, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8405232
Loss after updating value_net at epoch 700  is  tensor(0.4590, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.878713
Loss after updating value_net at epoch 800  is  tensor(0.4582, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8267965
Loss after updating value_net at epoch 900  is  tensor(0.4571, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.865508
Loss after updating value_net at epoch 1000  is  tensor(0.4566, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.843358
Loss after updating value_net at epoch 1100  is  tensor(0.4562, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7883363
Loss after updating value_net at epoch 1200  is  tensor(0.4554, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8158703
Loss after updating value_net at epoch 1300  is  tensor(0.4550, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7749023
Loss after updating value_net at epoch 1400  is  tensor(0.4545, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7682614
Loss after updating value_net at epoch 1500  is  tensor(0.4540, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.805837
Loss after updating value_net at epoch 1600  is  tensor(0.4535, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.82481
Loss after updating value_net at epoch 1700  is  tensor(0.4521, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.9819555
Loss after updating value_net at epoch 1800  is  tensor(0.4514, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.1205997
Loss after updating value_net at epoch 1900  is  tensor(0.4509, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.1859617
Loss after updating value_net at epoch 2000  is  tensor(0.4504, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2022896
Setup:
Num neurons :  [7, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 5910
Train loss =  tensor(0.4562, grad_fn=<NllLossBackward0>)
Num_train_data= 26931
Test error= 1790
Num_test_data= 8081
Test accuracy= 77.84927607969311
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5517, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.124279
Loss after updating value_net at epoch 100  is  tensor(0.4991, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.574162
Loss after updating value_net at epoch 200  is  tensor(0.4950, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2842078
Loss after updating value_net at epoch 300  is  tensor(0.4923, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2152271
Loss after updating value_net at epoch 400  is  tensor(0.4905, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2006683
Loss after updating value_net at epoch 500  is  tensor(0.4896, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1896853
Loss after updating value_net at epoch 600  is  tensor(0.4890, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.191289
Loss after updating value_net at epoch 700  is  tensor(0.4885, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.206153
Loss after updating value_net at epoch 800  is  tensor(0.4873, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.223798
Loss after updating value_net at epoch 900  is  tensor(0.4875, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1935642
Loss after updating value_net at epoch 1000  is  tensor(0.4874, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1835365
Loss after updating value_net at epoch 1100  is  tensor(0.4875, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1719525
Loss after updating value_net at epoch 1200  is  tensor(0.4873, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1684809
Loss after updating value_net at epoch 1300  is  tensor(0.4871, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.156857
Loss after updating value_net at epoch 1400  is  tensor(0.4867, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.16928
Loss after updating value_net at epoch 1500  is  tensor(0.4867, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1596558
Loss after updating value_net at epoch 1600  is  tensor(0.4852, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1983893
Loss after updating value_net at epoch 1700  is  tensor(0.4846, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.202777
Loss after updating value_net at epoch 1800  is  tensor(0.4844, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1963909
Loss after updating value_net at epoch 1900  is  tensor(0.4841, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2065606
Loss after updating value_net at epoch 2000  is  tensor(0.4836, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.21922
Setup:
Num neurons :  [7, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 6936
Train loss =  tensor(0.5284, grad_fn=<NllLossBackward0>)
Num_train_data= 26931
Test error= 2048
Num_test_data= 8081
Test accuracy= 74.65660190570475
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5453, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4212744
Loss after updating value_net at epoch 100  is  tensor(0.4942, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7647693
Loss after updating value_net at epoch 200  is  tensor(0.4879, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5673625
Loss after updating value_net at epoch 300  is  tensor(0.4854, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4578972
Loss after updating value_net at epoch 400  is  tensor(0.4845, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3735335
Loss after updating value_net at epoch 500  is  tensor(0.4837, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3201075
Loss after updating value_net at epoch 600  is  tensor(0.4835, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2767453
Loss after updating value_net at epoch 700  is  tensor(0.4820, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3163764
Loss after updating value_net at epoch 800  is  tensor(0.4818, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3188827
Loss after updating value_net at epoch 900  is  tensor(0.4820, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2940207
Loss after updating value_net at epoch 1000  is  tensor(0.4807, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3189547
Loss after updating value_net at epoch 1100  is  tensor(0.4806, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3057313
Loss after updating value_net at epoch 1200  is  tensor(0.4800, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.32503
Loss after updating value_net at epoch 1300  is  tensor(0.4796, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3445187
Loss after updating value_net at epoch 1400  is  tensor(0.4796, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.322141
Loss after updating value_net at epoch 1500  is  tensor(0.4793, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3331902
Loss after updating value_net at epoch 1600  is  tensor(0.4789, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3444328
Loss after updating value_net at epoch 1700  is  tensor(0.4783, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3748937
Loss after updating value_net at epoch 1800  is  tensor(0.4791, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3270833
Loss after updating value_net at epoch 1900  is  tensor(0.4791, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3109107
Loss after updating value_net at epoch 2000  is  tensor(0.4786, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.342212
Setup:
Num neurons :  [7, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 6452
Train loss =  tensor(0.4850, grad_fn=<NllLossBackward0>)
Num_train_data= 26931
Test error= 1929
Num_test_data= 8081
Test accuracy= 76.12919193169162
Maximum test accuracy for electricity is 78.04727137730478
Current task:  7
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361066
Task URL.............: https://www.openml.org/t/361066
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: Class
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:bank-marketing
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4796, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.032715
Loss after updating value_net at epoch 100  is  tensor(0.4533, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.4566107
Loss after updating value_net at epoch 200  is  tensor(0.4488, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4169946
Loss after updating value_net at epoch 300  is  tensor(0.4466, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.9420123
Loss after updating value_net at epoch 400  is  tensor(0.4452, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.711851
Loss after updating value_net at epoch 500  is  tensor(0.4442, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.536094
Loss after updating value_net at epoch 600  is  tensor(0.4431, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.465298
Loss after updating value_net at epoch 700  is  tensor(0.4413, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.455142
Loss after updating value_net at epoch 800  is  tensor(0.4397, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4785185
Loss after updating value_net at epoch 900  is  tensor(0.4383, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.507221
Loss after updating value_net at epoch 1000  is  tensor(0.4370, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.5309973
Loss after updating value_net at epoch 1100  is  tensor(0.4360, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.548289
Loss after updating value_net at epoch 1200  is  tensor(0.4352, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.526153
Loss after updating value_net at epoch 1300  is  tensor(0.4344, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.541991
Loss after updating value_net at epoch 1400  is  tensor(0.4337, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.5587044
Loss after updating value_net at epoch 1500  is  tensor(0.4334, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.514847
Loss after updating value_net at epoch 1600  is  tensor(0.4328, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.538332
Loss after updating value_net at epoch 1700  is  tensor(0.4325, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.523138
Loss after updating value_net at epoch 1800  is  tensor(0.4317, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.5562735
Loss after updating value_net at epoch 1900  is  tensor(0.4313, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.5609055
Loss after updating value_net at epoch 2000  is  tensor(0.4309, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.5740504
Setup:
Num neurons :  [7, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1485
Train loss =  tensor(0.4463, grad_fn=<NllLossBackward0>)
Num_train_data= 7404
Test error= 490
Num_test_data= 2222
Test accuracy= 77.94779477947795
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4763, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.2590694
Loss after updating value_net at epoch 100  is  tensor(0.4559, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.8803086
Loss after updating value_net at epoch 200  is  tensor(0.4502, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.277079
Loss after updating value_net at epoch 300  is  tensor(0.4473, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.974308
Loss after updating value_net at epoch 400  is  tensor(0.4453, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.732854
Loss after updating value_net at epoch 500  is  tensor(0.4436, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.6148434
Loss after updating value_net at epoch 600  is  tensor(0.4425, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4873214
Loss after updating value_net at epoch 700  is  tensor(0.4419, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4071665
Loss after updating value_net at epoch 800  is  tensor(0.4409, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3799734
Loss after updating value_net at epoch 900  is  tensor(0.4407, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.309739
Loss after updating value_net at epoch 1000  is  tensor(0.4401, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.2890177
Loss after updating value_net at epoch 1100  is  tensor(0.4391, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.324623
Loss after updating value_net at epoch 1200  is  tensor(0.4380, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3910832
Loss after updating value_net at epoch 1300  is  tensor(0.4368, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.376541
Loss after updating value_net at epoch 1400  is  tensor(0.4356, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.436224
Loss after updating value_net at epoch 1500  is  tensor(0.4348, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4422655
Loss after updating value_net at epoch 1600  is  tensor(0.4346, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4460306
Loss after updating value_net at epoch 1700  is  tensor(0.4337, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.493504
Loss after updating value_net at epoch 1800  is  tensor(0.4332, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.512541
Loss after updating value_net at epoch 1900  is  tensor(0.4326, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.527291
Loss after updating value_net at epoch 2000  is  tensor(0.4326, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.55519
Setup:
Num neurons :  [7, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1460
Train loss =  tensor(0.4391, grad_fn=<NllLossBackward0>)
Num_train_data= 7404
Test error= 498
Num_test_data= 2222
Test accuracy= 77.58775877587759
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5296, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8416831
Loss after updating value_net at epoch 100  is  tensor(0.4720, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0272822
Loss after updating value_net at epoch 200  is  tensor(0.4662, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6932428
Loss after updating value_net at epoch 300  is  tensor(0.4643, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5317316
Loss after updating value_net at epoch 400  is  tensor(0.4634, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4634688
Loss after updating value_net at epoch 500  is  tensor(0.4627, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4206076
Loss after updating value_net at epoch 600  is  tensor(0.4617, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4110253
Loss after updating value_net at epoch 700  is  tensor(0.4606, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4086177
Loss after updating value_net at epoch 800  is  tensor(0.4599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4109447
Loss after updating value_net at epoch 900  is  tensor(0.4594, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.398948
Loss after updating value_net at epoch 1000  is  tensor(0.4587, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4135318
Loss after updating value_net at epoch 1100  is  tensor(0.4582, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4119945
Loss after updating value_net at epoch 1200  is  tensor(0.4581, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3994043
Loss after updating value_net at epoch 1300  is  tensor(0.4578, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.39971
Loss after updating value_net at epoch 1400  is  tensor(0.4576, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3943682
Loss after updating value_net at epoch 1500  is  tensor(0.4577, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3850756
Loss after updating value_net at epoch 1600  is  tensor(0.4571, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.394664
Loss after updating value_net at epoch 1700  is  tensor(0.4569, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3804874
Loss after updating value_net at epoch 1800  is  tensor(0.4569, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3741255
Loss after updating value_net at epoch 1900  is  tensor(0.4566, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.376957
Loss after updating value_net at epoch 2000  is  tensor(0.4564, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.374376
Setup:
Num neurons :  [7, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1547
Train loss =  tensor(0.4625, grad_fn=<NllLossBackward0>)
Num_train_data= 7404
Test error= 497
Num_test_data= 2222
Test accuracy= 77.63276327632764
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5167, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6931844
Loss after updating value_net at epoch 100  is  tensor(0.4713, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9566405
Loss after updating value_net at epoch 200  is  tensor(0.4672, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6178887
Loss after updating value_net at epoch 300  is  tensor(0.4659, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5052757
Loss after updating value_net at epoch 400  is  tensor(0.4651, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4465697
Loss after updating value_net at epoch 500  is  tensor(0.4646, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4075146
Loss after updating value_net at epoch 600  is  tensor(0.4646, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3654203
Loss after updating value_net at epoch 700  is  tensor(0.4647, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.335606
Loss after updating value_net at epoch 800  is  tensor(0.4644, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3166869
Loss after updating value_net at epoch 900  is  tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3294415
Loss after updating value_net at epoch 1000  is  tensor(0.4637, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.325461
Loss after updating value_net at epoch 1100  is  tensor(0.4634, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3224099
Loss after updating value_net at epoch 1200  is  tensor(0.4634, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3206608
Loss after updating value_net at epoch 1300  is  tensor(0.4631, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.307167
Loss after updating value_net at epoch 1400  is  tensor(0.4629, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2937806
Loss after updating value_net at epoch 1500  is  tensor(0.4622, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3105779
Loss after updating value_net at epoch 1600  is  tensor(0.4614, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3204455
Loss after updating value_net at epoch 1700  is  tensor(0.4613, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3071902
Loss after updating value_net at epoch 1800  is  tensor(0.4607, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.32381
Loss after updating value_net at epoch 1900  is  tensor(0.4603, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.32747
Loss after updating value_net at epoch 2000  is  tensor(0.4601, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.321888
Setup:
Num neurons :  [7, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1572
Train loss =  tensor(0.4640, grad_fn=<NllLossBackward0>)
Num_train_data= 7404
Test error= 495
Num_test_data= 2222
Test accuracy= 77.72277227722772
Maximum test accuracy for bank-marketing is 77.94779477947795
Current task:  8
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361273
Task URL.............: https://www.openml.org/t/361273
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: readmitted
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:Diabetes130US
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6646, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.3455952
Loss after updating value_net at epoch 100  is  tensor(0.6614, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.0476521
Loss after updating value_net at epoch 200  is  tensor(0.6608, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.90559125
Loss after updating value_net at epoch 300  is  tensor(0.6605, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.87844634
Loss after updating value_net at epoch 400  is  tensor(0.6603, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8362784
Loss after updating value_net at epoch 500  is  tensor(0.6603, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.83122873
Loss after updating value_net at epoch 600  is  tensor(0.6601, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8326746
Loss after updating value_net at epoch 700  is  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8272094
Loss after updating value_net at epoch 800  is  tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.82738245
Loss after updating value_net at epoch 900  is  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.82601064
Loss after updating value_net at epoch 1000  is  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8374763
Loss after updating value_net at epoch 1100  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8260164
Loss after updating value_net at epoch 1200  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.84493804
Loss after updating value_net at epoch 1300  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8749433
Loss after updating value_net at epoch 1400  is  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8364839
Loss after updating value_net at epoch 1500  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.859783
Loss after updating value_net at epoch 1600  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.84258914
Loss after updating value_net at epoch 1700  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8114916
Loss after updating value_net at epoch 1800  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8278165
Loss after updating value_net at epoch 1900  is  tensor(0.6595, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8525424
Loss after updating value_net at epoch 2000  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8373722
Setup:
Num neurons :  [7, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 19552
Train loss =  tensor(0.6597, grad_fn=<NllLossBackward0>)
Num_train_data= 49763
Test error= 5830
Num_test_data= 14929
Test accuracy= 60.948489517047356
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6650, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.4966388
Loss after updating value_net at epoch 100  is  tensor(0.6613, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.1335322
Loss after updating value_net at epoch 200  is  tensor(0.6606, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.9591253
Loss after updating value_net at epoch 300  is  tensor(0.6602, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.87414724
Loss after updating value_net at epoch 400  is  tensor(0.6601, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.85817677
Loss after updating value_net at epoch 500  is  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.9002785
Loss after updating value_net at epoch 600  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.92717016
Loss after updating value_net at epoch 700  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.9337999
Loss after updating value_net at epoch 800  is  tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.897735
Loss after updating value_net at epoch 900  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8906107
Loss after updating value_net at epoch 1000  is  tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.85366386
Loss after updating value_net at epoch 1100  is  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.83102787
Loss after updating value_net at epoch 1200  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8563669
Loss after updating value_net at epoch 1300  is  tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.899917
Loss after updating value_net at epoch 1400  is  tensor(0.6601, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.87356853
Loss after updating value_net at epoch 1500  is  tensor(0.6602, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.86719036
Loss after updating value_net at epoch 1600  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8880563
Loss after updating value_net at epoch 1700  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8859885
Loss after updating value_net at epoch 1800  is  tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.89638495
Loss after updating value_net at epoch 1900  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8889297
Loss after updating value_net at epoch 2000  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8994504
Setup:
Num neurons :  [7, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 19579
Train loss =  tensor(0.6601, grad_fn=<NllLossBackward0>)
Num_train_data= 49763
Test error= 5811
Num_test_data= 14929
Test accuracy= 61.075758590662474
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6754, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.52529144
Loss after updating value_net at epoch 100  is  tensor(0.6665, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.49192047
Loss after updating value_net at epoch 200  is  tensor(0.6662, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47912025
Loss after updating value_net at epoch 300  is  tensor(0.6660, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47404477
Loss after updating value_net at epoch 400  is  tensor(0.6658, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47550404
Loss after updating value_net at epoch 500  is  tensor(0.6657, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47581652
Loss after updating value_net at epoch 600  is  tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47621232
Loss after updating value_net at epoch 700  is  tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47512835
Loss after updating value_net at epoch 800  is  tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47558832
Loss after updating value_net at epoch 900  is  tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4726261
Loss after updating value_net at epoch 1000  is  tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47372803
Loss after updating value_net at epoch 1100  is  tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47326386
Loss after updating value_net at epoch 1200  is  tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47251827
Loss after updating value_net at epoch 1300  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4743528
Loss after updating value_net at epoch 1400  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4734876
Loss after updating value_net at epoch 1500  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47583354
Loss after updating value_net at epoch 1600  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47403502
Loss after updating value_net at epoch 1700  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.46975136
Loss after updating value_net at epoch 1800  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.46891338
Loss after updating value_net at epoch 1900  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47342902
Loss after updating value_net at epoch 2000  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4695828
Setup:
Num neurons :  [7, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 19660
Train loss =  tensor(0.6657, grad_fn=<NllLossBackward0>)
Num_train_data= 49763
Test error= 5853
Num_test_data= 14929
Test accuracy= 60.79442695425012
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6776, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.51587814
Loss after updating value_net at epoch 100  is  tensor(0.6668, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4815005
Loss after updating value_net at epoch 200  is  tensor(0.6666, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.46144256
Loss after updating value_net at epoch 300  is  tensor(0.6664, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.458803
Loss after updating value_net at epoch 400  is  tensor(0.6660, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.46940303
Loss after updating value_net at epoch 500  is  tensor(0.6657, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4755632
Loss after updating value_net at epoch 600  is  tensor(0.6657, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4722325
Loss after updating value_net at epoch 700  is  tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4735438
Loss after updating value_net at epoch 800  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.48140493
Loss after updating value_net at epoch 900  is  tensor(0.6651, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.48825383
Loss after updating value_net at epoch 1000  is  tensor(0.6652, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.48190817
Loss after updating value_net at epoch 1100  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47453532
Loss after updating value_net at epoch 1200  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47436553
Loss after updating value_net at epoch 1300  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47148374
Loss after updating value_net at epoch 1400  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47219938
Loss after updating value_net at epoch 1500  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47262248
Loss after updating value_net at epoch 1600  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4703117
Loss after updating value_net at epoch 1700  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4690942
Loss after updating value_net at epoch 1800  is  tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.46760792
Loss after updating value_net at epoch 1900  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.47145486
Loss after updating value_net at epoch 2000  is  tensor(0.6653, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.4697683
Setup:
Num neurons :  [7, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 19646
Train loss =  tensor(0.6663, grad_fn=<NllLossBackward0>)
Num_train_data= 49763
Test error= 5850
Num_test_data= 14929
Test accuracy= 60.814522071136714
Maximum test accuracy for Diabetes130US is 61.075758590662474
Current task:  9
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361277
Task URL.............: https://www.openml.org/t/361277
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: price_above_median
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:california
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.3928, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.846149
Loss after updating value_net at epoch 100  is  tensor(0.3304, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.444985
Loss after updating value_net at epoch 200  is  tensor(0.3163, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.324934
Loss after updating value_net at epoch 300  is  tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.64495
Loss after updating value_net at epoch 400  is  tensor(0.3067, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.314323
Loss after updating value_net at epoch 500  is  tensor(0.3042, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0447283
Loss after updating value_net at epoch 600  is  tensor(0.3025, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.803154
Loss after updating value_net at epoch 700  is  tensor(0.3002, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.7215767
Loss after updating value_net at epoch 800  is  tensor(0.2983, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.688133
Loss after updating value_net at epoch 900  is  tensor(0.2967, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.6121187
Loss after updating value_net at epoch 1000  is  tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.6277623
Loss after updating value_net at epoch 1100  is  tensor(0.2945, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5558743
Loss after updating value_net at epoch 1200  is  tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5922203
Loss after updating value_net at epoch 1300  is  tensor(0.2926, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5604153
Loss after updating value_net at epoch 1400  is  tensor(0.2918, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.56973
Loss after updating value_net at epoch 1500  is  tensor(0.2911, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.497035
Loss after updating value_net at epoch 1600  is  tensor(0.2904, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.4868536
Loss after updating value_net at epoch 1700  is  tensor(0.2899, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.4524684
Loss after updating value_net at epoch 1800  is  tensor(0.2893, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.4603043
Loss after updating value_net at epoch 1900  is  tensor(0.2888, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.487787
Loss after updating value_net at epoch 2000  is  tensor(0.2885, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.468971
Setup:
Num neurons :  [8, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1849
Train loss =  tensor(0.2884, grad_fn=<NllLossBackward0>)
Num_train_data= 14443
Test error= 566
Num_test_data= 4334
Test accuracy= 86.94047069681588
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.3924, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 12.554606
Loss after updating value_net at epoch 100  is  tensor(0.3277, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.856762
Loss after updating value_net at epoch 200  is  tensor(0.3158, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.725449
Loss after updating value_net at epoch 300  is  tensor(0.3103, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.022127
Loss after updating value_net at epoch 400  is  tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4436874
Loss after updating value_net at epoch 500  is  tensor(0.3039, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.130828
Loss after updating value_net at epoch 600  is  tensor(0.3017, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.91886
Loss after updating value_net at epoch 700  is  tensor(0.3000, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.8103614
Loss after updating value_net at epoch 800  is  tensor(0.2980, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.7841563
Loss after updating value_net at epoch 900  is  tensor(0.2967, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.675838
Loss after updating value_net at epoch 1000  is  tensor(0.2956, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.641684
Loss after updating value_net at epoch 1100  is  tensor(0.2949, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5385323
Loss after updating value_net at epoch 1200  is  tensor(0.2941, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5454926
Loss after updating value_net at epoch 1300  is  tensor(0.2930, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.600518
Loss after updating value_net at epoch 1400  is  tensor(0.2929, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5023365
Loss after updating value_net at epoch 1500  is  tensor(0.2920, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.554932
Loss after updating value_net at epoch 1600  is  tensor(0.2911, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.519359
Loss after updating value_net at epoch 1700  is  tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5685315
Loss after updating value_net at epoch 1800  is  tensor(0.2899, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.559581
Loss after updating value_net at epoch 1900  is  tensor(0.2894, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5115376
Loss after updating value_net at epoch 2000  is  tensor(0.2885, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.599454
Setup:
Num neurons :  [8, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1954
Train loss =  tensor(0.3016, grad_fn=<NllLossBackward0>)
Num_train_data= 14443
Test error= 592
Num_test_data= 4334
Test accuracy= 86.34056299030918
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4679, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3488283
Loss after updating value_net at epoch 100  is  tensor(0.3557, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.274458
Loss after updating value_net at epoch 200  is  tensor(0.3398, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.729456
Loss after updating value_net at epoch 300  is  tensor(0.3348, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4649572
Loss after updating value_net at epoch 400  is  tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.3340125
Loss after updating value_net at epoch 500  is  tensor(0.3305, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2772744
Loss after updating value_net at epoch 600  is  tensor(0.3290, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2440145
Loss after updating value_net at epoch 700  is  tensor(0.3279, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2216372
Loss after updating value_net at epoch 800  is  tensor(0.3268, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.200985
Loss after updating value_net at epoch 900  is  tensor(0.3257, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2023602
Loss after updating value_net at epoch 1000  is  tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1877937
Loss after updating value_net at epoch 1100  is  tensor(0.3242, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1918204
Loss after updating value_net at epoch 1200  is  tensor(0.3237, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1786456
Loss after updating value_net at epoch 1300  is  tensor(0.3233, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1649704
Loss after updating value_net at epoch 1400  is  tensor(0.3220, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2039895
Loss after updating value_net at epoch 1500  is  tensor(0.3218, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1853771
Loss after updating value_net at epoch 1600  is  tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1904452
Loss after updating value_net at epoch 1700  is  tensor(0.3216, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1784124
Loss after updating value_net at epoch 1800  is  tensor(0.3213, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1736474
Loss after updating value_net at epoch 1900  is  tensor(0.3208, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1795936
Loss after updating value_net at epoch 2000  is  tensor(0.3206, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1771479
Setup:
Num neurons :  [8, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2067
Train loss =  tensor(0.3252, grad_fn=<NllLossBackward0>)
Num_train_data= 14443
Test error= 627
Num_test_data= 4334
Test accuracy= 85.53299492385787
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4737, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4932213
Loss after updating value_net at epoch 100  is  tensor(0.3568, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3132854
Loss after updating value_net at epoch 200  is  tensor(0.3455, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6927023
Loss after updating value_net at epoch 300  is  tensor(0.3389, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4885
Loss after updating value_net at epoch 400  is  tensor(0.3348, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.340064
Loss after updating value_net at epoch 500  is  tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2811327
Loss after updating value_net at epoch 600  is  tensor(0.3302, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2467217
Loss after updating value_net at epoch 700  is  tensor(0.3289, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.2056394
Loss after updating value_net at epoch 800  is  tensor(0.3277, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1968737
Loss after updating value_net at epoch 900  is  tensor(0.3269, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1907425
Loss after updating value_net at epoch 1000  is  tensor(0.3256, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1980207
Loss after updating value_net at epoch 1100  is  tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1714652
Loss after updating value_net at epoch 1200  is  tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1849208
Loss after updating value_net at epoch 1300  is  tensor(0.3239, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1919878
Loss after updating value_net at epoch 1400  is  tensor(0.3242, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1789846
Loss after updating value_net at epoch 1500  is  tensor(0.3235, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1875033
Loss after updating value_net at epoch 1600  is  tensor(0.3234, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1436472
Loss after updating value_net at epoch 1700  is  tensor(0.3240, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.112906
Loss after updating value_net at epoch 1800  is  tensor(0.3225, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.14798
Loss after updating value_net at epoch 1900  is  tensor(0.3223, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1687372
Loss after updating value_net at epoch 2000  is  tensor(0.3217, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.1584358
Setup:
Num neurons :  [8, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2054
Train loss =  tensor(0.3225, grad_fn=<NllLossBackward0>)
Num_train_data= 14443
Test error= 629
Num_test_data= 4334
Test accuracy= 85.48684817720351
Maximum test accuracy for california is 86.94047069681588
Current task:  10
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361055
Task URL.............: https://www.openml.org/t/361055
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: SeriousDlqin2yrs
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:credit
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6116, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.5254626
Loss after updating value_net at epoch 100  is  tensor(0.5302, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.757716
Loss after updating value_net at epoch 200  is  tensor(0.5226, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.0765753
Loss after updating value_net at epoch 300  is  tensor(0.5179, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8205886
Loss after updating value_net at epoch 400  is  tensor(0.5148, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.631374
Loss after updating value_net at epoch 500  is  tensor(0.5125, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.491852
Loss after updating value_net at epoch 600  is  tensor(0.5110, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.381798
Loss after updating value_net at epoch 700  is  tensor(0.5097, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.2787557
Loss after updating value_net at epoch 800  is  tensor(0.5085, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1906233
Loss after updating value_net at epoch 900  is  tensor(0.5078, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.087279
Loss after updating value_net at epoch 1000  is  tensor(0.5071, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9561613
Loss after updating value_net at epoch 1100  is  tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8256016
Loss after updating value_net at epoch 1200  is  tensor(0.5060, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.704
Loss after updating value_net at epoch 1300  is  tensor(0.5055, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6248531
Loss after updating value_net at epoch 1400  is  tensor(0.5054, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5243516
Loss after updating value_net at epoch 1500  is  tensor(0.5051, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.442763
Loss after updating value_net at epoch 1600  is  tensor(0.5045, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4267387
Loss after updating value_net at epoch 1700  is  tensor(0.5042, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.3783565
Loss after updating value_net at epoch 1800  is  tensor(0.5036, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.3791263
Loss after updating value_net at epoch 1900  is  tensor(0.5030, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.3708375
Loss after updating value_net at epoch 2000  is  tensor(0.5023, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.3763862
Setup:
Num neurons :  [10, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2844
Train loss =  tensor(0.5023, grad_fn=<NllLossBackward0>)
Num_train_data= 11699
Test error= 879
Num_test_data= 3511
Test accuracy= 74.96439760751923
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.096364
Loss after updating value_net at epoch 100  is  tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.5891366
Loss after updating value_net at epoch 200  is  tensor(0.5206, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.9417095
Loss after updating value_net at epoch 300  is  tensor(0.5160, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.727425
Loss after updating value_net at epoch 400  is  tensor(0.5133, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.486006
Loss after updating value_net at epoch 500  is  tensor(0.5116, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3314743
Loss after updating value_net at epoch 600  is  tensor(0.5103, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.2385826
Loss after updating value_net at epoch 700  is  tensor(0.5094, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1551495
Loss after updating value_net at epoch 800  is  tensor(0.5084, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0954804
Loss after updating value_net at epoch 900  is  tensor(0.5075, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0414286
Loss after updating value_net at epoch 1000  is  tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.019767
Loss after updating value_net at epoch 1100  is  tensor(0.5058, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.986045
Loss after updating value_net at epoch 1200  is  tensor(0.5051, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9482725
Loss after updating value_net at epoch 1300  is  tensor(0.5045, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9131074
Loss after updating value_net at epoch 1400  is  tensor(0.5039, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.86407
Loss after updating value_net at epoch 1500  is  tensor(0.5033, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8327284
Loss after updating value_net at epoch 1600  is  tensor(0.5029, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7915077
Loss after updating value_net at epoch 1700  is  tensor(0.5023, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.770508
Loss after updating value_net at epoch 1800  is  tensor(0.5023, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.730754
Loss after updating value_net at epoch 1900  is  tensor(0.5021, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6669893
Loss after updating value_net at epoch 2000  is  tensor(0.5016, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6668296
Setup:
Num neurons :  [10, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2903
Train loss =  tensor(0.5109, grad_fn=<NllLossBackward0>)
Num_train_data= 11699
Test error= 919
Num_test_data= 3511
Test accuracy= 73.82512104813443
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6617, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.977542
Loss after updating value_net at epoch 100  is  tensor(0.5706, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8809173
Loss after updating value_net at epoch 200  is  tensor(0.5395, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1184902
Loss after updating value_net at epoch 300  is  tensor(0.5338, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0982666
Loss after updating value_net at epoch 400  is  tensor(0.5314, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0611074
Loss after updating value_net at epoch 500  is  tensor(0.5297, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0408497
Loss after updating value_net at epoch 600  is  tensor(0.5278, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.02852
Loss after updating value_net at epoch 700  is  tensor(0.5259, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0248694
Loss after updating value_net at epoch 800  is  tensor(0.5240, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0231342
Loss after updating value_net at epoch 900  is  tensor(0.5223, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0218973
Loss after updating value_net at epoch 1000  is  tensor(0.5208, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0101523
Loss after updating value_net at epoch 1100  is  tensor(0.5195, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9986422
Loss after updating value_net at epoch 1200  is  tensor(0.5186, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9829185
Loss after updating value_net at epoch 1300  is  tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9668677
Loss after updating value_net at epoch 1400  is  tensor(0.5172, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9482069
Loss after updating value_net at epoch 1500  is  tensor(0.5165, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9365096
Loss after updating value_net at epoch 1600  is  tensor(0.5161, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9139104
Loss after updating value_net at epoch 1700  is  tensor(0.5156, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9046874
Loss after updating value_net at epoch 1800  is  tensor(0.5150, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.896452
Loss after updating value_net at epoch 1900  is  tensor(0.5145, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8947867
Loss after updating value_net at epoch 2000  is  tensor(0.5141, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8904635
Setup:
Num neurons :  [10, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2924
Train loss =  tensor(0.5145, grad_fn=<NllLossBackward0>)
Num_train_data= 11699
Test error= 897
Num_test_data= 3511
Test accuracy= 74.45172315579606
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6571, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.09341
Loss after updating value_net at epoch 100  is  tensor(0.5657, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8981966
Loss after updating value_net at epoch 200  is  tensor(0.5371, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1070232
Loss after updating value_net at epoch 300  is  tensor(0.5319, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0952754
Loss after updating value_net at epoch 400  is  tensor(0.5295, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0455997
Loss after updating value_net at epoch 500  is  tensor(0.5272, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0372298
Loss after updating value_net at epoch 600  is  tensor(0.5255, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0144784
Loss after updating value_net at epoch 700  is  tensor(0.5238, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.012577
Loss after updating value_net at epoch 800  is  tensor(0.5224, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.0029464
Loss after updating value_net at epoch 900  is  tensor(0.5212, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9693877
Loss after updating value_net at epoch 1000  is  tensor(0.5199, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9592872
Loss after updating value_net at epoch 1100  is  tensor(0.5190, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9417032
Loss after updating value_net at epoch 1200  is  tensor(0.5183, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9364692
Loss after updating value_net at epoch 1300  is  tensor(0.5178, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9264127
Loss after updating value_net at epoch 1400  is  tensor(0.5174, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9164071
Loss after updating value_net at epoch 1500  is  tensor(0.5169, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9123862
Loss after updating value_net at epoch 1600  is  tensor(0.5163, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9258323
Loss after updating value_net at epoch 1700  is  tensor(0.5158, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.92714
Loss after updating value_net at epoch 1800  is  tensor(0.5153, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.93163
Loss after updating value_net at epoch 1900  is  tensor(0.5151, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9179425
Loss after updating value_net at epoch 2000  is  tensor(0.5146, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9201504
Setup:
Num neurons :  [10, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2935
Train loss =  tensor(0.5150, grad_fn=<NllLossBackward0>)
Num_train_data= 11699
Test error= 911
Num_test_data= 3511
Test accuracy= 74.0529763600114
Maximum test accuracy for credit is 74.96439760751923
Current task:  11
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361061
Task URL.............: https://www.openml.org/t/361061
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: Y
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:covertype
Current task:  12
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361065
Task URL.............: https://www.openml.org/t/361065
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: class
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:MagicTelescope
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4186, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.853946
Loss after updating value_net at epoch 100  is  tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.97538
Loss after updating value_net at epoch 200  is  tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.071077
Loss after updating value_net at epoch 300  is  tensor(0.3290, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.6871076
Loss after updating value_net at epoch 400  is  tensor(0.3260, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4967904
Loss after updating value_net at epoch 500  is  tensor(0.3241, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.3344517
Loss after updating value_net at epoch 600  is  tensor(0.3226, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.2227635
Loss after updating value_net at epoch 700  is  tensor(0.3210, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.192295
Loss after updating value_net at epoch 800  is  tensor(0.3196, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1979804
Loss after updating value_net at epoch 900  is  tensor(0.3187, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.174473
Loss after updating value_net at epoch 1000  is  tensor(0.3181, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.117027
Loss after updating value_net at epoch 1100  is  tensor(0.3171, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1771965
Loss after updating value_net at epoch 1200  is  tensor(0.3164, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1549516
Loss after updating value_net at epoch 1300  is  tensor(0.3161, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.109828
Loss after updating value_net at epoch 1400  is  tensor(0.3153, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1199856
Loss after updating value_net at epoch 1500  is  tensor(0.3148, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1165223
Loss after updating value_net at epoch 1600  is  tensor(0.3139, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1783557
Loss after updating value_net at epoch 1700  is  tensor(0.3132, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.200525
Loss after updating value_net at epoch 1800  is  tensor(0.3124, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.211187
Loss after updating value_net at epoch 1900  is  tensor(0.3120, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1985884
Loss after updating value_net at epoch 2000  is  tensor(0.3117, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.152561
Setup:
Num neurons :  [10, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1299
Train loss =  tensor(0.3158, grad_fn=<NllLossBackward0>)
Num_train_data= 9363
Test error= 440
Num_test_data= 2810
Test accuracy= 84.34163701067615
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4131, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.222089
Loss after updating value_net at epoch 100  is  tensor(0.3497, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.0377
Loss after updating value_net at epoch 200  is  tensor(0.3375, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.085797
Loss after updating value_net at epoch 300  is  tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.6023912
Loss after updating value_net at epoch 400  is  tensor(0.3291, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.3236194
Loss after updating value_net at epoch 500  is  tensor(0.3272, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1570635
Loss after updating value_net at epoch 600  is  tensor(0.3250, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0714107
Loss after updating value_net at epoch 700  is  tensor(0.3235, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0177784
Loss after updating value_net at epoch 800  is  tensor(0.3219, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0244155
Loss after updating value_net at epoch 900  is  tensor(0.3211, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.007785
Loss after updating value_net at epoch 1000  is  tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.9926186
Loss after updating value_net at epoch 1100  is  tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.9334874
Loss after updating value_net at epoch 1200  is  tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.9394927
Loss after updating value_net at epoch 1300  is  tensor(0.3189, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.945197
Loss after updating value_net at epoch 1400  is  tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.9501314
Loss after updating value_net at epoch 1500  is  tensor(0.3177, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.014765
Loss after updating value_net at epoch 1600  is  tensor(0.3170, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.029895
Loss after updating value_net at epoch 1700  is  tensor(0.3167, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.998073
Loss after updating value_net at epoch 1800  is  tensor(0.3160, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.068357
Loss after updating value_net at epoch 1900  is  tensor(0.3152, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0463967
Loss after updating value_net at epoch 2000  is  tensor(0.3149, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0476236
Setup:
Num neurons :  [10, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1345
Train loss =  tensor(0.3287, grad_fn=<NllLossBackward0>)
Num_train_data= 9363
Test error= 441
Num_test_data= 2810
Test accuracy= 84.30604982206405
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4886, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3229094
Loss after updating value_net at epoch 100  is  tensor(0.3864, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.2346344
Loss after updating value_net at epoch 200  is  tensor(0.3658, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1922455
Loss after updating value_net at epoch 300  is  tensor(0.3600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.107874
Loss after updating value_net at epoch 400  is  tensor(0.3569, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0705705
Loss after updating value_net at epoch 500  is  tensor(0.3550, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0406194
Loss after updating value_net at epoch 600  is  tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0190096
Loss after updating value_net at epoch 700  is  tensor(0.3532, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9856262
Loss after updating value_net at epoch 800  is  tensor(0.3522, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.993495
Loss after updating value_net at epoch 900  is  tensor(0.3520, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9689844
Loss after updating value_net at epoch 1000  is  tensor(0.3513, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9564624
Loss after updating value_net at epoch 1100  is  tensor(0.3513, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.926197
Loss after updating value_net at epoch 1200  is  tensor(0.3502, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9600897
Loss after updating value_net at epoch 1300  is  tensor(0.3506, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9227786
Loss after updating value_net at epoch 1400  is  tensor(0.3500, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9289258
Loss after updating value_net at epoch 1500  is  tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.935948
Loss after updating value_net at epoch 1600  is  tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9311178
Loss after updating value_net at epoch 1700  is  tensor(0.3492, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9216776
Loss after updating value_net at epoch 1800  is  tensor(0.3492, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9125686
Loss after updating value_net at epoch 1900  is  tensor(0.3489, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9124188
Loss after updating value_net at epoch 2000  is  tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9190536
Setup:
Num neurons :  [10, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1481
Train loss =  tensor(0.3655, grad_fn=<NllLossBackward0>)
Num_train_data= 9363
Test error= 455
Num_test_data= 2810
Test accuracy= 83.80782918149467
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4831, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8126726
Loss after updating value_net at epoch 100  is  tensor(0.3871, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.248717
Loss after updating value_net at epoch 200  is  tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.10973
Loss after updating value_net at epoch 300  is  tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.069605
Loss after updating value_net at epoch 400  is  tensor(0.3577, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0357347
Loss after updating value_net at epoch 500  is  tensor(0.3558, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.016446
Loss after updating value_net at epoch 600  is  tensor(0.3547, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9895658
Loss after updating value_net at epoch 700  is  tensor(0.3535, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9639554
Loss after updating value_net at epoch 800  is  tensor(0.3527, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9366574
Loss after updating value_net at epoch 900  is  tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9499934
Loss after updating value_net at epoch 1000  is  tensor(0.3500, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9757438
Loss after updating value_net at epoch 1100  is  tensor(0.3493, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.971246
Loss after updating value_net at epoch 1200  is  tensor(0.3486, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.995374
Loss after updating value_net at epoch 1300  is  tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9511406
Loss after updating value_net at epoch 1400  is  tensor(0.3482, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9886434
Loss after updating value_net at epoch 1500  is  tensor(0.3480, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9749427
Loss after updating value_net at epoch 1600  is  tensor(0.3481, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9448404
Loss after updating value_net at epoch 1700  is  tensor(0.3476, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9506965
Loss after updating value_net at epoch 1800  is  tensor(0.3472, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9497066
Loss after updating value_net at epoch 1900  is  tensor(0.3477, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.931863
Loss after updating value_net at epoch 2000  is  tensor(0.3466, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.965766
Setup:
Num neurons :  [10, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1437
Train loss =  tensor(0.3561, grad_fn=<NllLossBackward0>)
Num_train_data= 9363
Test error= 461
Num_test_data= 2810
Test accuracy= 83.59430604982207
Maximum test accuracy for MagicTelescope is 84.34163701067615
Current task:  13
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361063
Task URL.............: https://www.openml.org/t/361063
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: binaryClass
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:house_16H
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.3903, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 12.789711
Loss after updating value_net at epoch 100  is  tensor(0.3023, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.98854
Loss after updating value_net at epoch 200  is  tensor(0.2865, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.785237
Loss after updating value_net at epoch 300  is  tensor(0.2797, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.148164
Loss after updating value_net at epoch 400  is  tensor(0.2760, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.7587543
Loss after updating value_net at epoch 500  is  tensor(0.2727, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.576955
Loss after updating value_net at epoch 600  is  tensor(0.2701, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.5061255
Loss after updating value_net at epoch 700  is  tensor(0.2678, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4734206
Loss after updating value_net at epoch 800  is  tensor(0.2658, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4602346
Loss after updating value_net at epoch 900  is  tensor(0.2641, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4446955
Loss after updating value_net at epoch 1000  is  tensor(0.2623, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4748015
Loss after updating value_net at epoch 1100  is  tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4915156
Loss after updating value_net at epoch 1200  is  tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.59157
Loss after updating value_net at epoch 1300  is  tensor(0.2578, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.5752687
Loss after updating value_net at epoch 1400  is  tensor(0.2568, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.6035204
Loss after updating value_net at epoch 1500  is  tensor(0.2551, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.6836166
Loss after updating value_net at epoch 1600  is  tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.7707367
Loss after updating value_net at epoch 1700  is  tensor(0.2531, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.7624
Loss after updating value_net at epoch 1800  is  tensor(0.2523, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.7414455
Loss after updating value_net at epoch 1900  is  tensor(0.2514, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.750092
Loss after updating value_net at epoch 2000  is  tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.7891097
Setup:
Num neurons :  [16, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1189
Train loss =  tensor(0.2932, grad_fn=<NllLossBackward0>)
Num_train_data= 9441
Test error= 381
Num_test_data= 2834
Test accuracy= 86.5561044460127
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 13.067684
Loss after updating value_net at epoch 100  is  tensor(0.2953, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.082893
Loss after updating value_net at epoch 200  is  tensor(0.2781, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.919197
Loss after updating value_net at epoch 300  is  tensor(0.2707, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.390949
Loss after updating value_net at epoch 400  is  tensor(0.2659, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.128916
Loss after updating value_net at epoch 500  is  tensor(0.2621, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.020278
Loss after updating value_net at epoch 600  is  tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.070716
Loss after updating value_net at epoch 700  is  tensor(0.2552, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.123539
Loss after updating value_net at epoch 800  is  tensor(0.2532, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.174252
Loss after updating value_net at epoch 900  is  tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.143787
Loss after updating value_net at epoch 1000  is  tensor(0.2493, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.183176
Loss after updating value_net at epoch 1100  is  tensor(0.2472, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.242717
Loss after updating value_net at epoch 1200  is  tensor(0.2455, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.26588
Loss after updating value_net at epoch 1300  is  tensor(0.2440, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.312064
Loss after updating value_net at epoch 1400  is  tensor(0.2428, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.335484
Loss after updating value_net at epoch 1500  is  tensor(0.2415, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.423492
Loss after updating value_net at epoch 1600  is  tensor(0.2401, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.540919
Loss after updating value_net at epoch 1700  is  tensor(0.2399, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.483807
Loss after updating value_net at epoch 1800  is  tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.467693
Loss after updating value_net at epoch 1900  is  tensor(0.2374, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.536637
Loss after updating value_net at epoch 2000  is  tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.532768
Setup:
Num neurons :  [16, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1032
Train loss =  tensor(0.2608, grad_fn=<NllLossBackward0>)
Num_train_data= 9441
Test error= 375
Num_test_data= 2834
Test accuracy= 86.76781933662667
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4782, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.0726585
Loss after updating value_net at epoch 100  is  tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.287195
Loss after updating value_net at epoch 200  is  tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9685402
Loss after updating value_net at epoch 300  is  tensor(0.3139, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8369029
Loss after updating value_net at epoch 400  is  tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.739321
Loss after updating value_net at epoch 500  is  tensor(0.3094, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6641657
Loss after updating value_net at epoch 600  is  tensor(0.3066, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6744452
Loss after updating value_net at epoch 700  is  tensor(0.3056, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.6140604
Loss after updating value_net at epoch 800  is  tensor(0.3042, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.610021
Loss after updating value_net at epoch 900  is  tensor(0.3032, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5997632
Loss after updating value_net at epoch 1000  is  tensor(0.3025, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5948777
Loss after updating value_net at epoch 1100  is  tensor(0.3020, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5829806
Loss after updating value_net at epoch 1200  is  tensor(0.3012, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5920434
Loss after updating value_net at epoch 1300  is  tensor(0.3010, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5782278
Loss after updating value_net at epoch 1400  is  tensor(0.3003, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5888848
Loss after updating value_net at epoch 1500  is  tensor(0.2997, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5954738
Loss after updating value_net at epoch 1600  is  tensor(0.2996, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5793734
Loss after updating value_net at epoch 1700  is  tensor(0.2987, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.600161
Loss after updating value_net at epoch 1800  is  tensor(0.2982, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.615187
Loss after updating value_net at epoch 1900  is  tensor(0.2977, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.622749
Loss after updating value_net at epoch 2000  is  tensor(0.2978, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5990736
Setup:
Num neurons :  [16, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1165
Train loss =  tensor(0.3044, grad_fn=<NllLossBackward0>)
Num_train_data= 9441
Test error= 413
Num_test_data= 2834
Test accuracy= 85.42695836273818
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4696, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.084883
Loss after updating value_net at epoch 100  is  tensor(0.3275, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.320173
Loss after updating value_net at epoch 200  is  tensor(0.3136, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9571345
Loss after updating value_net at epoch 300  is  tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8314717
Loss after updating value_net at epoch 400  is  tensor(0.3052, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7938542
Loss after updating value_net at epoch 500  is  tensor(0.3029, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7740989
Loss after updating value_net at epoch 600  is  tensor(0.3007, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7617524
Loss after updating value_net at epoch 700  is  tensor(0.2983, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7857919
Loss after updating value_net at epoch 800  is  tensor(0.2966, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8003252
Loss after updating value_net at epoch 900  is  tensor(0.2950, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8142715
Loss after updating value_net at epoch 1000  is  tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.836561
Loss after updating value_net at epoch 1100  is  tensor(0.2922, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8522482
Loss after updating value_net at epoch 1200  is  tensor(0.2929, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7873745
Loss after updating value_net at epoch 1300  is  tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8610446
Loss after updating value_net at epoch 1400  is  tensor(0.2898, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8593483
Loss after updating value_net at epoch 1500  is  tensor(0.2898, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8293505
Loss after updating value_net at epoch 1600  is  tensor(0.2879, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.867171
Loss after updating value_net at epoch 1700  is  tensor(0.2876, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.866183
Loss after updating value_net at epoch 1800  is  tensor(0.2876, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8520732
Loss after updating value_net at epoch 1900  is  tensor(0.2864, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8859587
Loss after updating value_net at epoch 2000  is  tensor(0.2850, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9423685
Setup:
Num neurons :  [16, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1090
Train loss =  tensor(0.2893, grad_fn=<NllLossBackward0>)
Num_train_data= 9441
Test error= 398
Num_test_data= 2834
Test accuracy= 85.95624558927311
Maximum test accuracy for house_16H is 86.76781933662667
Current task:  14
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361070
Task URL.............: https://www.openml.org/t/361070
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: label
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:eye_movements
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6787, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.3381879
Loss after updating value_net at epoch 100  is  tensor(0.6467, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7723991
Loss after updating value_net at epoch 200  is  tensor(0.6301, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.661491
Loss after updating value_net at epoch 300  is  tensor(0.6150, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4975576
Loss after updating value_net at epoch 400  is  tensor(0.5996, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.508399
Loss after updating value_net at epoch 500  is  tensor(0.5827, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.5885277
Loss after updating value_net at epoch 600  is  tensor(0.5697, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.325865
Loss after updating value_net at epoch 700  is  tensor(0.5609, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.805277
Loss after updating value_net at epoch 800  is  tensor(0.5551, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0913286
Loss after updating value_net at epoch 900  is  tensor(0.5504, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.297521
Loss after updating value_net at epoch 1000  is  tensor(0.5464, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4792643
Loss after updating value_net at epoch 1100  is  tensor(0.5429, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.6405263
Loss after updating value_net at epoch 1200  is  tensor(0.5395, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.8004775
Loss after updating value_net at epoch 1300  is  tensor(0.5367, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.9157486
Loss after updating value_net at epoch 1400  is  tensor(0.5330, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.131097
Loss after updating value_net at epoch 1500  is  tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.386671
Loss after updating value_net at epoch 1600  is  tensor(0.5251, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.59613
Loss after updating value_net at epoch 1700  is  tensor(0.5219, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.761815
Loss after updating value_net at epoch 1800  is  tensor(0.5187, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.938997
Loss after updating value_net at epoch 1900  is  tensor(0.5162, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.051706
Loss after updating value_net at epoch 2000  is  tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.141762
Setup:
Num neurons :  [20, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2199
Train loss =  tensor(0.6746, grad_fn=<NllLossBackward0>)
Num_train_data= 5325
Test error= 736
Num_test_data= 1599
Test accuracy= 53.97123202001251
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6725, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8644248
Loss after updating value_net at epoch 100  is  tensor(0.6416, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.2155194
Loss after updating value_net at epoch 200  is  tensor(0.6255, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8389106
Loss after updating value_net at epoch 300  is  tensor(0.6069, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8239956
Loss after updating value_net at epoch 400  is  tensor(0.5929, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.549514
Loss after updating value_net at epoch 500  is  tensor(0.5829, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.090728
Loss after updating value_net at epoch 600  is  tensor(0.5751, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.499181
Loss after updating value_net at epoch 700  is  tensor(0.5697, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.7664742
Loss after updating value_net at epoch 800  is  tensor(0.5649, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.9857345
Loss after updating value_net at epoch 900  is  tensor(0.5609, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.1655354
Loss after updating value_net at epoch 1000  is  tensor(0.5581, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.267964
Loss after updating value_net at epoch 1100  is  tensor(0.5557, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.349351
Loss after updating value_net at epoch 1200  is  tensor(0.5530, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.4894996
Loss after updating value_net at epoch 1300  is  tensor(0.5487, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.802609
Loss after updating value_net at epoch 1400  is  tensor(0.5445, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0450716
Loss after updating value_net at epoch 1500  is  tensor(0.5388, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4430017
Loss after updating value_net at epoch 1600  is  tensor(0.5321, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.964936
Loss after updating value_net at epoch 1700  is  tensor(0.5271, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.277363
Loss after updating value_net at epoch 1800  is  tensor(0.5217, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.66246
Loss after updating value_net at epoch 1900  is  tensor(0.5179, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.90142
Loss after updating value_net at epoch 2000  is  tensor(0.5149, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.070204
Setup:
Num neurons :  [20, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1715
Train loss =  tensor(0.5898, grad_fn=<NllLossBackward0>)
Num_train_data= 5325
Test error= 697
Num_test_data= 1599
Test accuracy= 56.41025641025641
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6929, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.014721828
Loss after updating value_net at epoch 100  is  tensor(0.6814, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.29029426
Loss after updating value_net at epoch 200  is  tensor(0.6631, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.58976567
Loss after updating value_net at epoch 300  is  tensor(0.6580, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.6691487
Loss after updating value_net at epoch 400  is  tensor(0.6564, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.6885619
Loss after updating value_net at epoch 500  is  tensor(0.6554, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.6991315
Loss after updating value_net at epoch 600  is  tensor(0.6546, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7062099
Loss after updating value_net at epoch 700  is  tensor(0.6539, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.71341336
Loss after updating value_net at epoch 800  is  tensor(0.6535, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7158755
Loss after updating value_net at epoch 900  is  tensor(0.6531, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.71810234
Loss after updating value_net at epoch 1000  is  tensor(0.6527, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.72049594
Loss after updating value_net at epoch 1100  is  tensor(0.6523, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7231862
Loss after updating value_net at epoch 1200  is  tensor(0.6520, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7261355
Loss after updating value_net at epoch 1300  is  tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7259128
Loss after updating value_net at epoch 1400  is  tensor(0.6516, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.72769797
Loss after updating value_net at epoch 1500  is  tensor(0.6514, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7279057
Loss after updating value_net at epoch 1600  is  tensor(0.6512, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.72727025
Loss after updating value_net at epoch 1700  is  tensor(0.6510, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.72863114
Loss after updating value_net at epoch 1800  is  tensor(0.6509, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.72884446
Loss after updating value_net at epoch 1900  is  tensor(0.6507, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.7293117
Loss after updating value_net at epoch 2000  is  tensor(0.6506, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.72984016
Setup:
Num neurons :  [20, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2189
Train loss =  tensor(0.6753, grad_fn=<NllLossBackward0>)
Num_train_data= 5325
Test error= 721
Num_test_data= 1599
Test accuracy= 54.90931832395247
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6919, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.05928561
Loss after updating value_net at epoch 100  is  tensor(0.6766, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.41029847
Loss after updating value_net at epoch 200  is  tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.6862264
Loss after updating value_net at epoch 300  is  tensor(0.6542, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.78198355
Loss after updating value_net at epoch 400  is  tensor(0.6527, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8017317
Loss after updating value_net at epoch 500  is  tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8080833
Loss after updating value_net at epoch 600  is  tensor(0.6511, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.81187
Loss after updating value_net at epoch 700  is  tensor(0.6506, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.81488895
Loss after updating value_net at epoch 800  is  tensor(0.6499, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.81954575
Loss after updating value_net at epoch 900  is  tensor(0.6495, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.82373214
Loss after updating value_net at epoch 1000  is  tensor(0.6490, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.82736015
Loss after updating value_net at epoch 1100  is  tensor(0.6486, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.83238435
Loss after updating value_net at epoch 1200  is  tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.83746785
Loss after updating value_net at epoch 1300  is  tensor(0.6478, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.84081143
Loss after updating value_net at epoch 1400  is  tensor(0.6476, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.84338033
Loss after updating value_net at epoch 1500  is  tensor(0.6473, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8467295
Loss after updating value_net at epoch 1600  is  tensor(0.6469, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.8520852
Loss after updating value_net at epoch 1700  is  tensor(0.6466, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.85591936
Loss after updating value_net at epoch 1800  is  tensor(0.6464, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.85897005
Loss after updating value_net at epoch 1900  is  tensor(0.6462, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.86107415
Loss after updating value_net at epoch 2000  is  tensor(0.6460, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.862654
Setup:
Num neurons :  [20, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2180
Train loss =  tensor(0.6746, grad_fn=<NllLossBackward0>)
Num_train_data= 5325
Test error= 705
Num_test_data= 1599
Test accuracy= 55.909943714821765
Maximum test accuracy for eye_movements is 56.41025641025641
Current task:  15
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361275
Task URL.............: https://www.openml.org/t/361275
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: y
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:default-of-credit-card-clients
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5952, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7554035
Loss after updating value_net at epoch 100  is  tensor(0.5608, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.765655
Loss after updating value_net at epoch 200  is  tensor(0.5519, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7250676
Loss after updating value_net at epoch 300  is  tensor(0.5461, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7704566
Loss after updating value_net at epoch 400  is  tensor(0.5415, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8371706
Loss after updating value_net at epoch 500  is  tensor(0.5382, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.899952
Loss after updating value_net at epoch 600  is  tensor(0.5360, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.920814
Loss after updating value_net at epoch 700  is  tensor(0.5340, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.990993
Loss after updating value_net at epoch 800  is  tensor(0.5326, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.021282
Loss after updating value_net at epoch 900  is  tensor(0.5311, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0699615
Loss after updating value_net at epoch 1000  is  tensor(0.5296, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.154912
Loss after updating value_net at epoch 1100  is  tensor(0.5284, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1990285
Loss after updating value_net at epoch 1200  is  tensor(0.5270, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.245531
Loss after updating value_net at epoch 1300  is  tensor(0.5260, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.266595
Loss after updating value_net at epoch 1400  is  tensor(0.5249, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.307946
Loss after updating value_net at epoch 1500  is  tensor(0.5240, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.326233
Loss after updating value_net at epoch 1600  is  tensor(0.5233, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3557343
Loss after updating value_net at epoch 1700  is  tensor(0.5225, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.362791
Loss after updating value_net at epoch 1800  is  tensor(0.5219, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3764963
Loss after updating value_net at epoch 1900  is  tensor(0.5215, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.366978
Loss after updating value_net at epoch 2000  is  tensor(0.5211, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.3639784
Setup:
Num neurons :  [20, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2548
Train loss =  tensor(0.5412, grad_fn=<NllLossBackward0>)
Num_train_data= 9290
Test error= 844
Num_test_data= 2788
Test accuracy= 69.7274031563845
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5884, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9327824
Loss after updating value_net at epoch 100  is  tensor(0.5627, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4910586
Loss after updating value_net at epoch 200  is  tensor(0.5539, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4176931
Loss after updating value_net at epoch 300  is  tensor(0.5494, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.4166627
Loss after updating value_net at epoch 400  is  tensor(0.5457, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.475184
Loss after updating value_net at epoch 500  is  tensor(0.5429, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.5423944
Loss after updating value_net at epoch 600  is  tensor(0.5403, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.607531
Loss after updating value_net at epoch 700  is  tensor(0.5383, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.658525
Loss after updating value_net at epoch 800  is  tensor(0.5361, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.741621
Loss after updating value_net at epoch 900  is  tensor(0.5341, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.807464
Loss after updating value_net at epoch 1000  is  tensor(0.5325, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8603742
Loss after updating value_net at epoch 1100  is  tensor(0.5312, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9056454
Loss after updating value_net at epoch 1200  is  tensor(0.5299, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.976835
Loss after updating value_net at epoch 1300  is  tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.043371
Loss after updating value_net at epoch 1400  is  tensor(0.5277, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1155195
Loss after updating value_net at epoch 1500  is  tensor(0.5266, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1727285
Loss after updating value_net at epoch 1600  is  tensor(0.5254, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.283608
Loss after updating value_net at epoch 1700  is  tensor(0.5246, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.306086
Loss after updating value_net at epoch 1800  is  tensor(0.5235, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.376048
Loss after updating value_net at epoch 1900  is  tensor(0.5229, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4125404
Loss after updating value_net at epoch 2000  is  tensor(0.5221, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.469777
Setup:
Num neurons :  [20, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2506
Train loss =  tensor(0.5324, grad_fn=<NllLossBackward0>)
Num_train_data= 9290
Test error= 841
Num_test_data= 2788
Test accuracy= 69.83500717360116
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6269, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7834941
Loss after updating value_net at epoch 100  is  tensor(0.5780, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6080315
Loss after updating value_net at epoch 200  is  tensor(0.5726, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5717058
Loss after updating value_net at epoch 300  is  tensor(0.5702, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5614693
Loss after updating value_net at epoch 400  is  tensor(0.5684, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5678217
Loss after updating value_net at epoch 500  is  tensor(0.5670, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5634625
Loss after updating value_net at epoch 600  is  tensor(0.5657, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5770919
Loss after updating value_net at epoch 700  is  tensor(0.5649, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5690702
Loss after updating value_net at epoch 800  is  tensor(0.5644, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5678198
Loss after updating value_net at epoch 900  is  tensor(0.5637, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5731976
Loss after updating value_net at epoch 1000  is  tensor(0.5633, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5726964
Loss after updating value_net at epoch 1100  is  tensor(0.5628, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5728804
Loss after updating value_net at epoch 1200  is  tensor(0.5622, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5786359
Loss after updating value_net at epoch 1300  is  tensor(0.5620, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5696824
Loss after updating value_net at epoch 1400  is  tensor(0.5616, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5772578
Loss after updating value_net at epoch 1500  is  tensor(0.5614, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5735598
Loss after updating value_net at epoch 1600  is  tensor(0.5612, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5711265
Loss after updating value_net at epoch 1700  is  tensor(0.5606, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5839875
Loss after updating value_net at epoch 1800  is  tensor(0.5605, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.576231
Loss after updating value_net at epoch 1900  is  tensor(0.5602, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5780388
Loss after updating value_net at epoch 2000  is  tensor(0.5600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.5798929
Setup:
Num neurons :  [20, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2791
Train loss =  tensor(0.5620, grad_fn=<NllLossBackward0>)
Num_train_data= 9290
Test error= 869
Num_test_data= 2788
Test accuracy= 68.83070301291248
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6120, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8057375
Loss after updating value_net at epoch 100  is  tensor(0.5755, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6502013
Loss after updating value_net at epoch 200  is  tensor(0.5691, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6326693
Loss after updating value_net at epoch 300  is  tensor(0.5659, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6326917
Loss after updating value_net at epoch 400  is  tensor(0.5636, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6497177
Loss after updating value_net at epoch 500  is  tensor(0.5622, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6493518
Loss after updating value_net at epoch 600  is  tensor(0.5612, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6563591
Loss after updating value_net at epoch 700  is  tensor(0.5605, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6581435
Loss after updating value_net at epoch 800  is  tensor(0.5597, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6618637
Loss after updating value_net at epoch 900  is  tensor(0.5590, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.66652
Loss after updating value_net at epoch 1000  is  tensor(0.5585, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6625003
Loss after updating value_net at epoch 1100  is  tensor(0.5576, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6830121
Loss after updating value_net at epoch 1200  is  tensor(0.5577, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6598521
Loss after updating value_net at epoch 1300  is  tensor(0.5573, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6691384
Loss after updating value_net at epoch 1400  is  tensor(0.5569, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6728506
Loss after updating value_net at epoch 1500  is  tensor(0.5564, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.683745
Loss after updating value_net at epoch 1600  is  tensor(0.5565, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6741298
Loss after updating value_net at epoch 1700  is  tensor(0.5565, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6616243
Loss after updating value_net at epoch 1800  is  tensor(0.5560, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6730705
Loss after updating value_net at epoch 1900  is  tensor(0.5555, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6918879
Loss after updating value_net at epoch 2000  is  tensor(0.5555, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.6809918
Setup:
Num neurons :  [20, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 2775
Train loss =  tensor(0.5555, grad_fn=<NllLossBackward0>)
Num_train_data= 9290
Test error= 869
Num_test_data= 2788
Test accuracy= 68.83070301291248
Maximum test accuracy for default-of-credit-card-clients is 69.83500717360116
Current task:  16
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361278
Task URL.............: https://www.openml.org/t/361278
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: RiskPerformance
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:heloc
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5635, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.096804
Loss after updating value_net at epoch 100  is  tensor(0.5331, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7335224
Loss after updating value_net at epoch 200  is  tensor(0.5219, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.6154375
Loss after updating value_net at epoch 300  is  tensor(0.5142, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.635028
Loss after updating value_net at epoch 400  is  tensor(0.5074, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.7476735
Loss after updating value_net at epoch 500  is  tensor(0.5014, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.872543
Loss after updating value_net at epoch 600  is  tensor(0.4965, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.0060024
Loss after updating value_net at epoch 700  is  tensor(0.4926, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.140218
Loss after updating value_net at epoch 800  is  tensor(0.4891, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.253289
Loss after updating value_net at epoch 900  is  tensor(0.4861, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.348096
Loss after updating value_net at epoch 1000  is  tensor(0.4836, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4061174
Loss after updating value_net at epoch 1100  is  tensor(0.4812, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4840417
Loss after updating value_net at epoch 1200  is  tensor(0.4789, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.567701
Loss after updating value_net at epoch 1300  is  tensor(0.4766, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.646672
Loss after updating value_net at epoch 1400  is  tensor(0.4746, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.7188706
Loss after updating value_net at epoch 1500  is  tensor(0.4729, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.786297
Loss after updating value_net at epoch 1600  is  tensor(0.4711, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.8588457
Loss after updating value_net at epoch 1700  is  tensor(0.4697, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.9015017
Loss after updating value_net at epoch 1800  is  tensor(0.4682, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.9531126
Loss after updating value_net at epoch 1900  is  tensor(0.4669, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.9895625
Loss after updating value_net at epoch 2000  is  tensor(0.4656, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.0271397
Setup:
Num neurons :  [22, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1963
Train loss =  tensor(0.5549, grad_fn=<NllLossBackward0>)
Num_train_data= 7000
Test error= 612
Num_test_data= 2100
Test accuracy= 70.85714285714286
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5630, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8650665
Loss after updating value_net at epoch 100  is  tensor(0.5313, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.58202
Loss after updating value_net at epoch 200  is  tensor(0.5172, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.6147094
Loss after updating value_net at epoch 300  is  tensor(0.5069, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.8098
Loss after updating value_net at epoch 400  is  tensor(0.4976, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.208181
Loss after updating value_net at epoch 500  is  tensor(0.4879, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.624962
Loss after updating value_net at epoch 600  is  tensor(0.4803, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.922588
Loss after updating value_net at epoch 700  is  tensor(0.4746, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.1635313
Loss after updating value_net at epoch 800  is  tensor(0.4698, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.3691835
Loss after updating value_net at epoch 900  is  tensor(0.4650, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.610808
Loss after updating value_net at epoch 1000  is  tensor(0.4607, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.8235145
Loss after updating value_net at epoch 1100  is  tensor(0.4565, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0598063
Loss after updating value_net at epoch 1200  is  tensor(0.4524, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.347014
Loss after updating value_net at epoch 1300  is  tensor(0.4485, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.621901
Loss after updating value_net at epoch 1400  is  tensor(0.4446, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.885812
Loss after updating value_net at epoch 1500  is  tensor(0.4409, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.079781
Loss after updating value_net at epoch 1600  is  tensor(0.4376, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.273801
Loss after updating value_net at epoch 1700  is  tensor(0.4349, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.37168
Loss after updating value_net at epoch 1800  is  tensor(0.4325, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.517516
Loss after updating value_net at epoch 1900  is  tensor(0.4302, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.635377
Loss after updating value_net at epoch 2000  is  tensor(0.4278, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.799997
Setup:
Num neurons :  [22, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1922
Train loss =  tensor(0.5403, grad_fn=<NllLossBackward0>)
Num_train_data= 7000
Test error= 598
Num_test_data= 2100
Test accuracy= 71.52380952380952
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5907, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7564285
Loss after updating value_net at epoch 100  is  tensor(0.5473, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.1920068
Loss after updating value_net at epoch 200  is  tensor(0.5414, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9962106
Loss after updating value_net at epoch 300  is  tensor(0.5383, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9054505
Loss after updating value_net at epoch 400  is  tensor(0.5356, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8845086
Loss after updating value_net at epoch 500  is  tensor(0.5334, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8845769
Loss after updating value_net at epoch 600  is  tensor(0.5314, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8971901
Loss after updating value_net at epoch 700  is  tensor(0.5297, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.912701
Loss after updating value_net at epoch 800  is  tensor(0.5284, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9157043
Loss after updating value_net at epoch 900  is  tensor(0.5273, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9197719
Loss after updating value_net at epoch 1000  is  tensor(0.5264, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9244463
Loss after updating value_net at epoch 1100  is  tensor(0.5256, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9267013
Loss after updating value_net at epoch 1200  is  tensor(0.5248, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9348899
Loss after updating value_net at epoch 1300  is  tensor(0.5242, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9351047
Loss after updating value_net at epoch 1400  is  tensor(0.5234, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9467587
Loss after updating value_net at epoch 1500  is  tensor(0.5227, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9580853
Loss after updating value_net at epoch 1600  is  tensor(0.5219, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9666333
Loss after updating value_net at epoch 1700  is  tensor(0.5213, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9740187
Loss after updating value_net at epoch 1800  is  tensor(0.5209, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9750583
Loss after updating value_net at epoch 1900  is  tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9768765
Loss after updating value_net at epoch 2000  is  tensor(0.5198, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.9906297
Setup:
Num neurons :  [22, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1941
Train loss =  tensor(0.5471, grad_fn=<NllLossBackward0>)
Num_train_data= 7000
Test error= 604
Num_test_data= 2100
Test accuracy= 71.23809523809524
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5913, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.179565
Loss after updating value_net at epoch 100  is  tensor(0.5504, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8789271
Loss after updating value_net at epoch 200  is  tensor(0.5446, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7629554
Loss after updating value_net at epoch 300  is  tensor(0.5409, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7338078
Loss after updating value_net at epoch 400  is  tensor(0.5387, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7170618
Loss after updating value_net at epoch 500  is  tensor(0.5367, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.721311
Loss after updating value_net at epoch 600  is  tensor(0.5346, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7206126
Loss after updating value_net at epoch 700  is  tensor(0.5329, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7412863
Loss after updating value_net at epoch 800  is  tensor(0.5318, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7403822
Loss after updating value_net at epoch 900  is  tensor(0.5305, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7569437
Loss after updating value_net at epoch 1000  is  tensor(0.5298, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7506391
Loss after updating value_net at epoch 1100  is  tensor(0.5294, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7470322
Loss after updating value_net at epoch 1200  is  tensor(0.5285, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7533689
Loss after updating value_net at epoch 1300  is  tensor(0.5274, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7844304
Loss after updating value_net at epoch 1400  is  tensor(0.5270, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7813275
Loss after updating value_net at epoch 1500  is  tensor(0.5266, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7785589
Loss after updating value_net at epoch 1600  is  tensor(0.5260, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7894025
Loss after updating value_net at epoch 1700  is  tensor(0.5253, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8009079
Loss after updating value_net at epoch 1800  is  tensor(0.5249, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8082924
Loss after updating value_net at epoch 1900  is  tensor(0.5248, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.7926003
Loss after updating value_net at epoch 2000  is  tensor(0.5244, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.803367
Setup:
Num neurons :  [22, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 1966
Train loss =  tensor(0.5513, grad_fn=<NllLossBackward0>)
Num_train_data= 7000
Test error= 596
Num_test_data= 2100
Test accuracy= 71.61904761904762
Maximum test accuracy for heloc is 71.61904761904762
Current task:  17
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361069
Task URL.............: https://www.openml.org/t/361069
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: target
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:Higgs
Current task:  18
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361062
Task URL.............: https://www.openml.org/t/361062
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: binaryClass
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:pol
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.2252, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 20.30961
Loss after updating value_net at epoch 100  is  tensor(0.0792, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.797842
Loss after updating value_net at epoch 200  is  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.82994
Loss after updating value_net at epoch 300  is  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.255342
Loss after updating value_net at epoch 400  is  tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.992651
Loss after updating value_net at epoch 500  is  tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.778511
Loss after updating value_net at epoch 600  is  tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.670627
Loss after updating value_net at epoch 700  is  tensor(0.0395, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.60326
Loss after updating value_net at epoch 800  is  tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.703552
Loss after updating value_net at epoch 900  is  tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.549864
Loss after updating value_net at epoch 1000  is  tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.424594
Loss after updating value_net at epoch 1100  is  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.436344
Loss after updating value_net at epoch 1200  is  tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.373273
Loss after updating value_net at epoch 1300  is  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.403505
Loss after updating value_net at epoch 1400  is  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.363532
Loss after updating value_net at epoch 1500  is  tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.437706
Loss after updating value_net at epoch 1600  is  tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.269328
Loss after updating value_net at epoch 1700  is  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.326608
Loss after updating value_net at epoch 1800  is  tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.361641
Loss after updating value_net at epoch 1900  is  tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.303386
Loss after updating value_net at epoch 2000  is  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.19757
Setup:
Num neurons :  [26, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 32
Train loss =  tensor(0.0303, grad_fn=<NllLossBackward0>)
Num_train_data= 7057
Test error= 40
Num_test_data= 2118
Test accuracy= 98.11142587346554
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.2332, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 19.620174
Loss after updating value_net at epoch 100  is  tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.802128
Loss after updating value_net at epoch 200  is  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.9552
Loss after updating value_net at epoch 300  is  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.465979
Loss after updating value_net at epoch 400  is  tensor(0.0467, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.038623
Loss after updating value_net at epoch 500  is  tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.826498
Loss after updating value_net at epoch 600  is  tensor(0.0409, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.640514
Loss after updating value_net at epoch 700  is  tensor(0.0398, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.566612
Loss after updating value_net at epoch 800  is  tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.626538
Loss after updating value_net at epoch 900  is  tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.475986
Loss after updating value_net at epoch 1000  is  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.500868
Loss after updating value_net at epoch 1100  is  tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.406197
Loss after updating value_net at epoch 1200  is  tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.290623
Loss after updating value_net at epoch 1300  is  tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.371177
Loss after updating value_net at epoch 1400  is  tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.348696
Loss after updating value_net at epoch 1500  is  tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.315817
Loss after updating value_net at epoch 1600  is  tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.39534
Loss after updating value_net at epoch 1700  is  tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.340373
Loss after updating value_net at epoch 1800  is  tensor(0.0302, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.251284
Loss after updating value_net at epoch 1900  is  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.271733
Loss after updating value_net at epoch 2000  is  tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.100723
Setup:
Num neurons :  [26, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 47
Train loss =  tensor(0.0355, grad_fn=<NllLossBackward0>)
Num_train_data= 7057
Test error= 31
Num_test_data= 2118
Test accuracy= 98.53635505193579
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.3654, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.175697
Loss after updating value_net at epoch 100  is  tensor(0.1305, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.706066
Loss after updating value_net at epoch 200  is  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4515195
Loss after updating value_net at epoch 300  is  tensor(0.0860, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.419717
Loss after updating value_net at epoch 400  is  tensor(0.0795, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.398788
Loss after updating value_net at epoch 500  is  tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.399407
Loss after updating value_net at epoch 600  is  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.366315
Loss after updating value_net at epoch 700  is  tensor(0.0714, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.317274
Loss after updating value_net at epoch 800  is  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.31695
Loss after updating value_net at epoch 900  is  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.329707
Loss after updating value_net at epoch 1000  is  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.332128
Loss after updating value_net at epoch 1100  is  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2998114
Loss after updating value_net at epoch 1200  is  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.310152
Loss after updating value_net at epoch 1300  is  tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3028665
Loss after updating value_net at epoch 1400  is  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2711105
Loss after updating value_net at epoch 1500  is  tensor(0.0635, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2850566
Loss after updating value_net at epoch 1600  is  tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2799973
Loss after updating value_net at epoch 1700  is  tensor(0.0613, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3215165
Loss after updating value_net at epoch 1800  is  tensor(0.0609, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.331989
Loss after updating value_net at epoch 1900  is  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.295075
Loss after updating value_net at epoch 2000  is  tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3451796
Setup:
Num neurons :  [26, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 69
Train loss =  tensor(0.0609, grad_fn=<NllLossBackward0>)
Num_train_data= 7057
Test error= 31
Num_test_data= 2118
Test accuracy= 98.53635505193579
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.3624, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.882265
Loss after updating value_net at epoch 100  is  tensor(0.1265, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.973265
Loss after updating value_net at epoch 200  is  tensor(0.0959, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.637407
Loss after updating value_net at epoch 300  is  tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.524534
Loss after updating value_net at epoch 400  is  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.474989
Loss after updating value_net at epoch 500  is  tensor(0.0772, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.396865
Loss after updating value_net at epoch 600  is  tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.352589
Loss after updating value_net at epoch 700  is  tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3927503
Loss after updating value_net at epoch 800  is  tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3750863
Loss after updating value_net at epoch 900  is  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.40401
Loss after updating value_net at epoch 1000  is  tensor(0.0693, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3269467
Loss after updating value_net at epoch 1100  is  tensor(0.0671, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4025
Loss after updating value_net at epoch 1200  is  tensor(0.0685, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2993975
Loss after updating value_net at epoch 1300  is  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2731996
Loss after updating value_net at epoch 1400  is  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3145905
Loss after updating value_net at epoch 1500  is  tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3370385
Loss after updating value_net at epoch 1600  is  tensor(0.0646, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.339387
Loss after updating value_net at epoch 1700  is  tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.267552
Loss after updating value_net at epoch 1800  is  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.2813354
Loss after updating value_net at epoch 1900  is  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.314922
Loss after updating value_net at epoch 2000  is  tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.23889
Setup:
Num neurons :  [26, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 79
Train loss =  tensor(0.0636, grad_fn=<NllLossBackward0>)
Num_train_data= 7057
Test error= 35
Num_test_data= 2118
Test accuracy= 98.34749763928234
Maximum test accuracy for pol is 98.53635505193579
Current task:  19
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361068
Task URL.............: https://www.openml.org/t/361068
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: signal
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:MiniBooNE
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4100, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 14.08732
Loss after updating value_net at epoch 100  is  tensor(0.2584, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.81469
Loss after updating value_net at epoch 200  is  tensor(0.2361, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.485025
Loss after updating value_net at epoch 300  is  tensor(0.2201, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.661085
Loss after updating value_net at epoch 400  is  tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.2067795
Loss after updating value_net at epoch 500  is  tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.912314
Loss after updating value_net at epoch 600  is  tensor(0.2009, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.7864637
Loss after updating value_net at epoch 700  is  tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.639642
Loss after updating value_net at epoch 800  is  tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.55426
Loss after updating value_net at epoch 900  is  tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4788914
Loss after updating value_net at epoch 1000  is  tensor(0.1928, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.31828
Loss after updating value_net at epoch 1100  is  tensor(0.1913, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.2867255
Loss after updating value_net at epoch 1200  is  tensor(0.1902, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.1451406
Loss after updating value_net at epoch 1300  is  tensor(0.1890, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.083294
Loss after updating value_net at epoch 1400  is  tensor(0.1884, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.951037
Loss after updating value_net at epoch 1500  is  tensor(0.1875, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.9126406
Loss after updating value_net at epoch 1600  is  tensor(0.1870, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.827592
Loss after updating value_net at epoch 1700  is  tensor(0.1864, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.7415657
Loss after updating value_net at epoch 1800  is  tensor(0.1862, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.6484065
Loss after updating value_net at epoch 1900  is  tensor(0.1858, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.615566
Loss after updating value_net at epoch 2000  is  tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.6151557
Setup:
Num neurons :  [50, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 3622
Train loss =  tensor(0.1860, grad_fn=<NllLossBackward0>)
Num_train_data= 51098
Test error= 1081
Num_test_data= 15331
Test accuracy= 92.94892701063205
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4136, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.04566
Loss after updating value_net at epoch 100  is  tensor(0.2543, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.875687
Loss after updating value_net at epoch 200  is  tensor(0.2295, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.430004
Loss after updating value_net at epoch 300  is  tensor(0.2173, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.197531
Loss after updating value_net at epoch 400  is  tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.960439
Loss after updating value_net at epoch 500  is  tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.704133
Loss after updating value_net at epoch 600  is  tensor(0.2020, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.4647455
Loss after updating value_net at epoch 700  is  tensor(0.1993, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.322634
Loss after updating value_net at epoch 800  is  tensor(0.1961, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.06099
Loss after updating value_net at epoch 900  is  tensor(0.1946, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.8555756
Loss after updating value_net at epoch 1000  is  tensor(0.1931, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.638434
Loss after updating value_net at epoch 1100  is  tensor(0.1918, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.5085955
Loss after updating value_net at epoch 1200  is  tensor(0.1909, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.3503532
Loss after updating value_net at epoch 1300  is  tensor(0.1899, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.244609
Loss after updating value_net at epoch 1400  is  tensor(0.1886, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.206373
Loss after updating value_net at epoch 1500  is  tensor(0.1877, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0000496
Loss after updating value_net at epoch 1600  is  tensor(0.1873, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.048462
Loss after updating value_net at epoch 1700  is  tensor(0.1865, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.035253
Loss after updating value_net at epoch 1800  is  tensor(0.1860, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.045616
Loss after updating value_net at epoch 1900  is  tensor(0.1852, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.9785814
Loss after updating value_net at epoch 2000  is  tensor(0.1847, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.954413
Setup:
Num neurons :  [50, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 3678
Train loss =  tensor(0.1887, grad_fn=<NllLossBackward0>)
Num_train_data= 51098
Test error= 1104
Num_test_data= 15331
Test accuracy= 92.79890418107104
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5092, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.9571023
Loss after updating value_net at epoch 100  is  tensor(0.2916, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.9513907
Loss after updating value_net at epoch 200  is  tensor(0.2646, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.380595
Loss after updating value_net at epoch 300  is  tensor(0.2484, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.096936
Loss after updating value_net at epoch 400  is  tensor(0.2413, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9410582
Loss after updating value_net at epoch 500  is  tensor(0.2367, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8595066
Loss after updating value_net at epoch 600  is  tensor(0.2321, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.838675
Loss after updating value_net at epoch 700  is  tensor(0.2275, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8583806
Loss after updating value_net at epoch 800  is  tensor(0.2233, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8842764
Loss after updating value_net at epoch 900  is  tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.888386
Loss after updating value_net at epoch 1000  is  tensor(0.2176, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.890267
Loss after updating value_net at epoch 1100  is  tensor(0.2155, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.882902
Loss after updating value_net at epoch 1200  is  tensor(0.2137, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8866851
Loss after updating value_net at epoch 1300  is  tensor(0.2119, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8960428
Loss after updating value_net at epoch 1400  is  tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.871516
Loss after updating value_net at epoch 1500  is  tensor(0.2093, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8787355
Loss after updating value_net at epoch 1600  is  tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8618743
Loss after updating value_net at epoch 1700  is  tensor(0.2073, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8699274
Loss after updating value_net at epoch 1800  is  tensor(0.2063, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8646843
Loss after updating value_net at epoch 1900  is  tensor(0.2057, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.834985
Loss after updating value_net at epoch 2000  is  tensor(0.2047, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8412564
Setup:
Num neurons :  [50, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 3867
Train loss =  tensor(0.2056, grad_fn=<NllLossBackward0>)
Num_train_data= 51098
Test error= 1134
Num_test_data= 15331
Test accuracy= 92.60322222946971
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.090939
Loss after updating value_net at epoch 100  is  tensor(0.2766, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.4766474
Loss after updating value_net at epoch 200  is  tensor(0.2577, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.1301804
Loss after updating value_net at epoch 300  is  tensor(0.2475, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9272275
Loss after updating value_net at epoch 400  is  tensor(0.2393, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9012802
Loss after updating value_net at epoch 500  is  tensor(0.2334, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9082487
Loss after updating value_net at epoch 600  is  tensor(0.2284, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.927076
Loss after updating value_net at epoch 700  is  tensor(0.2247, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.923667
Loss after updating value_net at epoch 800  is  tensor(0.2216, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.931233
Loss after updating value_net at epoch 900  is  tensor(0.2187, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.94163
Loss after updating value_net at epoch 1000  is  tensor(0.2169, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.935299
Loss after updating value_net at epoch 1100  is  tensor(0.2148, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.924814
Loss after updating value_net at epoch 1200  is  tensor(0.2135, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9041815
Loss after updating value_net at epoch 1300  is  tensor(0.2116, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.92088
Loss after updating value_net at epoch 1400  is  tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9054508
Loss after updating value_net at epoch 1500  is  tensor(0.2089, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.9218678
Loss after updating value_net at epoch 1600  is  tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8994665
Loss after updating value_net at epoch 1700  is  tensor(0.2072, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.892582
Loss after updating value_net at epoch 1800  is  tensor(0.2068, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8594368
Loss after updating value_net at epoch 1900  is  tensor(0.2063, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.8413565
Loss after updating value_net at epoch 2000  is  tensor(0.2054, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.838334
Setup:
Num neurons :  [50, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 3897
Train loss =  tensor(0.2053, grad_fn=<NllLossBackward0>)
Num_train_data= 51098
Test error= 1125
Num_test_data= 15331
Test accuracy= 92.6619268149501
Maximum test accuracy for MiniBooNE is 92.94892701063205
Current task:  20
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361274
Task URL.............: https://www.openml.org/t/361274
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: class
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:jannis
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5652, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.175863
Loss after updating value_net at epoch 100  is  tensor(0.4534, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.663926
Loss after updating value_net at epoch 200  is  tensor(0.4336, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.3236575
Loss after updating value_net at epoch 300  is  tensor(0.4222, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.932049
Loss after updating value_net at epoch 400  is  tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.257978
Loss after updating value_net at epoch 500  is  tensor(0.4105, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.791512
Loss after updating value_net at epoch 600  is  tensor(0.4063, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.111491
Loss after updating value_net at epoch 700  is  tensor(0.4032, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.223034
Loss after updating value_net at epoch 800  is  tensor(0.4014, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.251639
Loss after updating value_net at epoch 900  is  tensor(0.3997, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.260569
Loss after updating value_net at epoch 1000  is  tensor(0.3972, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.418051
Loss after updating value_net at epoch 1100  is  tensor(0.3947, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.6131115
Loss after updating value_net at epoch 1200  is  tensor(0.3928, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.747547
Loss after updating value_net at epoch 1300  is  tensor(0.3913, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.80316
Loss after updating value_net at epoch 1400  is  tensor(0.3903, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.882723
Loss after updating value_net at epoch 1500  is  tensor(0.3892, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.9778805
Loss after updating value_net at epoch 1600  is  tensor(0.3882, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.001142
Loss after updating value_net at epoch 1700  is  tensor(0.3872, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.042325
Loss after updating value_net at epoch 1800  is  tensor(0.3865, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.06798
Loss after updating value_net at epoch 1900  is  tensor(0.3856, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.105589
Loss after updating value_net at epoch 2000  is  tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.135875
Setup:
Num neurons :  [54, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 8043
Train loss =  tensor(0.4367, grad_fn=<NllLossBackward0>)
Num_train_data= 40306
Test error= 2678
Num_test_data= 12092
Test accuracy= 77.85312603374132
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5629, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.0218477
Loss after updating value_net at epoch 100  is  tensor(0.4462, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.4259515
Loss after updating value_net at epoch 200  is  tensor(0.4258, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 7.8976793
Loss after updating value_net at epoch 300  is  tensor(0.4165, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.172192
Loss after updating value_net at epoch 400  is  tensor(0.4104, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.553798
Loss after updating value_net at epoch 500  is  tensor(0.4048, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 8.963718
Loss after updating value_net at epoch 600  is  tensor(0.3992, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 9.605617
Loss after updating value_net at epoch 700  is  tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.273668
Loss after updating value_net at epoch 800  is  tensor(0.3904, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.73134
Loss after updating value_net at epoch 900  is  tensor(0.3883, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 10.939445
Loss after updating value_net at epoch 1000  is  tensor(0.3865, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.007676
Loss after updating value_net at epoch 1100  is  tensor(0.3849, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.057396
Loss after updating value_net at epoch 1200  is  tensor(0.3831, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.189068
Loss after updating value_net at epoch 1300  is  tensor(0.3817, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.268923
Loss after updating value_net at epoch 1400  is  tensor(0.3802, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.413418
Loss after updating value_net at epoch 1500  is  tensor(0.3789, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.489094
Loss after updating value_net at epoch 1600  is  tensor(0.3777, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.534373
Loss after updating value_net at epoch 1700  is  tensor(0.3764, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.667267
Loss after updating value_net at epoch 1800  is  tensor(0.3753, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.704161
Loss after updating value_net at epoch 1900  is  tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.762351
Loss after updating value_net at epoch 2000  is  tensor(0.3734, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 11.83348
Setup:
Num neurons :  [54, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 7306
Train loss =  tensor(0.4062, grad_fn=<NllLossBackward0>)
Num_train_data= 40306
Test error= 2718
Num_test_data= 12092
Test accuracy= 77.52232881243798
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.5968, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6379304
Loss after updating value_net at epoch 100  is  tensor(0.4927, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4282012
Loss after updating value_net at epoch 200  is  tensor(0.4831, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.4336996
Loss after updating value_net at epoch 300  is  tensor(0.4785, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.481385
Loss after updating value_net at epoch 400  is  tensor(0.4758, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5183902
Loss after updating value_net at epoch 500  is  tensor(0.4736, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5506604
Loss after updating value_net at epoch 600  is  tensor(0.4713, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5759137
Loss after updating value_net at epoch 700  is  tensor(0.4691, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6120024
Loss after updating value_net at epoch 800  is  tensor(0.4674, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6313324
Loss after updating value_net at epoch 900  is  tensor(0.4662, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6447053
Loss after updating value_net at epoch 1000  is  tensor(0.4649, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6756203
Loss after updating value_net at epoch 1100  is  tensor(0.4649, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6594486
Loss after updating value_net at epoch 1200  is  tensor(0.4638, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6778412
Loss after updating value_net at epoch 1300  is  tensor(0.4629, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7013037
Loss after updating value_net at epoch 1400  is  tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.705567
Loss after updating value_net at epoch 1500  is  tensor(0.4618, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.710708
Loss after updating value_net at epoch 1600  is  tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7290769
Loss after updating value_net at epoch 1700  is  tensor(0.4612, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7113004
Loss after updating value_net at epoch 1800  is  tensor(0.4605, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7205408
Loss after updating value_net at epoch 1900  is  tensor(0.4601, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.724431
Loss after updating value_net at epoch 2000  is  tensor(0.4599, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.720236
Setup:
Num neurons :  [54, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 8806
Train loss =  tensor(0.4599, grad_fn=<NllLossBackward0>)
Num_train_data= 40306
Test error= 2818
Num_test_data= 12092
Test accuracy= 76.69533575917963
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6046, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.308753
Loss after updating value_net at epoch 100  is  tensor(0.4926, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.3911586
Loss after updating value_net at epoch 200  is  tensor(0.4790, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.5420437
Loss after updating value_net at epoch 300  is  tensor(0.4724, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6279879
Loss after updating value_net at epoch 400  is  tensor(0.4687, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6669047
Loss after updating value_net at epoch 500  is  tensor(0.4667, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.6715262
Loss after updating value_net at epoch 600  is  tensor(0.4643, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7238784
Loss after updating value_net at epoch 700  is  tensor(0.4626, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7461927
Loss after updating value_net at epoch 800  is  tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7796123
Loss after updating value_net at epoch 900  is  tensor(0.4607, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7676215
Loss after updating value_net at epoch 1000  is  tensor(0.4600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7584698
Loss after updating value_net at epoch 1100  is  tensor(0.4594, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7663832
Loss after updating value_net at epoch 1200  is  tensor(0.4585, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7773163
Loss after updating value_net at epoch 1300  is  tensor(0.4576, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.796863
Loss after updating value_net at epoch 1400  is  tensor(0.4576, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8117058
Loss after updating value_net at epoch 1500  is  tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7872088
Loss after updating value_net at epoch 1600  is  tensor(0.4568, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7959168
Loss after updating value_net at epoch 1700  is  tensor(0.4560, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8067994
Loss after updating value_net at epoch 1800  is  tensor(0.4558, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8116698
Loss after updating value_net at epoch 1900  is  tensor(0.4556, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8062813
Loss after updating value_net at epoch 2000  is  tensor(0.4555, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.7927744
Setup:
Num neurons :  [54, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 8987
Train loss =  tensor(0.4672, grad_fn=<NllLossBackward0>)
Num_train_data= 40306
Test error= 2871
Num_test_data= 12092
Test accuracy= 76.25702944095269
Maximum test accuracy for jannis is 77.85312603374132
Current task:  21
OpenML Classification Task
==========================
Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION
Task ID..............: 361276
Task URL.............: https://www.openml.org/t/361276
Estimation Procedure.: crossvalidation
Evaluation Measure...: predictive_accuracy
Target Feature.......: target
# of Classes.........: 2
Cost Matrix..........: Available
Current Dataset:Bioresponse
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6038, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.7442617
Loss after updating value_net at epoch 100  is  tensor(0.1637, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.627535
Loss after updating value_net at epoch 200  is  tensor(0.0937, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.4743567
Loss after updating value_net at epoch 300  is  tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.388755
Loss after updating value_net at epoch 400  is  tensor(0.0715, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.194608
Loss after updating value_net at epoch 500  is  tensor(0.0661, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.0805473
Loss after updating value_net at epoch 600  is  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.892945
Loss after updating value_net at epoch 700  is  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.867682
Loss after updating value_net at epoch 800  is  tensor(0.0612, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.769774
Loss after updating value_net at epoch 900  is  tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.716402
Loss after updating value_net at epoch 1000  is  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.7321925
Loss after updating value_net at epoch 1100  is  tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.5852547
Loss after updating value_net at epoch 1200  is  tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.5709443
Loss after updating value_net at epoch 1300  is  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.491868
Loss after updating value_net at epoch 1400  is  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4528694
Loss after updating value_net at epoch 1500  is  tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4612603
Loss after updating value_net at epoch 1600  is  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4347634
Loss after updating value_net at epoch 1700  is  tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.375032
Loss after updating value_net at epoch 1800  is  tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3897843
Loss after updating value_net at epoch 1900  is  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4466486
Loss after updating value_net at epoch 2000  is  tensor(0.0606, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.380141
Setup:
Num neurons :  [419, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 70
Train loss =  tensor(0.0591, grad_fn=<NllLossBackward0>)
Num_train_data= 2403
Test error= 181
Num_test_data= 722
Test accuracy= 74.93074792243767
Logistic regression 0.03, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6029, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 4.0524435
Loss after updating value_net at epoch 100  is  tensor(0.1295, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.183117
Loss after updating value_net at epoch 200  is  tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.7258205
Loss after updating value_net at epoch 300  is  tensor(0.0616, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.505803
Loss after updating value_net at epoch 400  is  tensor(0.0544, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.3894014
Loss after updating value_net at epoch 500  is  tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 6.0395927
Loss after updating value_net at epoch 600  is  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.9311113
Loss after updating value_net at epoch 700  is  tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.837264
Loss after updating value_net at epoch 800  is  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.7724857
Loss after updating value_net at epoch 900  is  tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.622042
Loss after updating value_net at epoch 1000  is  tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.544329
Loss after updating value_net at epoch 1100  is  tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.5524282
Loss after updating value_net at epoch 1200  is  tensor(0.0460, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.6034217
Loss after updating value_net at epoch 1300  is  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.484758
Loss after updating value_net at epoch 1400  is  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.402066
Loss after updating value_net at epoch 1500  is  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4231367
Loss after updating value_net at epoch 1600  is  tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.4622264
Loss after updating value_net at epoch 1700  is  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3211575
Loss after updating value_net at epoch 1800  is  tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.413392
Loss after updating value_net at epoch 1900  is  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3093843
Loss after updating value_net at epoch 2000  is  tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 5.3771954
Setup:
Num neurons :  [419, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 201
Train loss =  tensor(0.2559, grad_fn=<NllLossBackward0>)
Num_train_data= 2403
Test error= 161
Num_test_data= 722
Test accuracy= 77.70083102493075
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 20
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6916, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.036293082
Loss after updating value_net at epoch 100  is  tensor(0.4901, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8828835
Loss after updating value_net at epoch 200  is  tensor(0.2577, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.647313
Loss after updating value_net at epoch 300  is  tensor(0.2224, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8216128
Loss after updating value_net at epoch 400  is  tensor(0.2095, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8581796
Loss after updating value_net at epoch 500  is  tensor(0.2013, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.864616
Loss after updating value_net at epoch 600  is  tensor(0.1963, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8672142
Loss after updating value_net at epoch 700  is  tensor(0.1932, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8595972
Loss after updating value_net at epoch 800  is  tensor(0.1890, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.860384
Loss after updating value_net at epoch 900  is  tensor(0.1877, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8255336
Loss after updating value_net at epoch 1000  is  tensor(0.1850, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8528852
Loss after updating value_net at epoch 1100  is  tensor(0.1828, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.858049
Loss after updating value_net at epoch 1200  is  tensor(0.1823, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8466995
Loss after updating value_net at epoch 1300  is  tensor(0.1810, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.855805
Loss after updating value_net at epoch 1400  is  tensor(0.1808, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.847406
Loss after updating value_net at epoch 1500  is  tensor(0.1801, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.850916
Loss after updating value_net at epoch 1600  is  tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8509197
Loss after updating value_net at epoch 1700  is  tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8457003
Loss after updating value_net at epoch 1800  is  tensor(0.1795, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8484378
Loss after updating value_net at epoch 1900  is  tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8415287
Loss after updating value_net at epoch 2000  is  tensor(0.1793, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.8233886
Setup:
Num neurons :  [419, 20, 20, 20, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 273
Train loss =  tensor(0.2019, grad_fn=<NllLossBackward0>)
Num_train_data= 2403
Test error= 173
Num_test_data= 722
Test accuracy= 76.0387811634349
Logistic regression 0.01, Learning rate 0.001, Number of layers 3 and number of neurons 25
DLGN performance
Loss after updating value_net at epoch 0  is  tensor(0.6925, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 0.015276072
Loss after updating value_net at epoch 100  is  tensor(0.4996, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 1.8469564
Loss after updating value_net at epoch 200  is  tensor(0.2427, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.779358
Loss after updating value_net at epoch 300  is  tensor(0.2090, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9453845
Loss after updating value_net at epoch 400  is  tensor(0.1942, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0018706
Loss after updating value_net at epoch 500  is  tensor(0.1861, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0093145
Loss after updating value_net at epoch 600  is  tensor(0.1787, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0502844
Loss after updating value_net at epoch 700  is  tensor(0.1760, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0464127
Loss after updating value_net at epoch 800  is  tensor(0.1735, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0495248
Loss after updating value_net at epoch 900  is  tensor(0.1728, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0246983
Loss after updating value_net at epoch 1000  is  tensor(0.1730, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9939048
Loss after updating value_net at epoch 1100  is  tensor(0.1706, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.0278733
Loss after updating value_net at epoch 1200  is  tensor(0.1713, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9880667
Loss after updating value_net at epoch 1300  is  tensor(0.1700, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 3.005214
Loss after updating value_net at epoch 1400  is  tensor(0.1715, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9641283
Loss after updating value_net at epoch 1500  is  tensor(0.1708, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9686928
Loss after updating value_net at epoch 1600  is  tensor(0.1695, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9926233
Loss after updating value_net at epoch 1700  is  tensor(0.1694, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.989966
Loss after updating value_net at epoch 1800  is  tensor(0.1694, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9818969
Loss after updating value_net at epoch 1900  is  tensor(0.1689, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9807186
Loss after updating value_net at epoch 2000  is  tensor(0.1692, device='cuda:0', grad_fn=<NllLossBackward0>)
Total path abs value 2.9712415
Setup:
Num neurons :  [419, 25, 25, 25, 1]
 Beta : 3.0
 lr : 0.001
=======================
[]
==========Best validated model=============
Train error= 330
Train loss =  tensor(0.3590, grad_fn=<NllLossBackward0>)
Num_train_data= 2403
Test error= 172
Num_test_data= 722
Test accuracy= 76.17728531855956
Maximum test accuracy for Bioresponse is 77.70083102493075
